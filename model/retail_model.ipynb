{
 "cells": [
  {
   "cell_type": "code",
   "id": "acea67b8044b9002",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import holidays\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import  numpy as np\n",
    "import sqlite3\n",
    "import os\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "path=pd.read_csv(r\"/database/data\\retail_data\\products.csv\")\n",
    "df=pd.DataFrame(path)\n"
   ],
   "id": "83d8050e72b6dd3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9779ade78c705210",
   "metadata": {},
   "source": [
    "# Connect to SQLite database\n",
    "db_path = r\"C:\\Users\\kingd\\Ennovar\\database\\database.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Read data from database tables\n",
    "x = pd.read_sql_query(\"SELECT * FROM transactions\", conn)\n",
    "y = pd.read_sql_query(\"SELECT * FROM products\", conn)\n",
    "\n",
    "transactions = pd.DataFrame(x)\n",
    "products = pd.DataFrame(y)\n",
    "\n",
    "conn.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1f1e1f74a6369399",
   "metadata": {},
   "source": [
    "transactions.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eea3a54d",
   "metadata": {},
   "source": [
    "products.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2d97bd863fe17efa",
   "metadata": {},
   "source": [
    "merged = pd.merge(df1, df2, on=\"Product ID\", how=\"inner\")\n",
    "merged=merged[merged['Currency']=='USD']\n",
    "merged"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bdd160ea52c798d4",
   "metadata": {},
   "source": [
    "### Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "64bfc3b28a8e72e5",
   "metadata": {},
   "source": [
    "df=merged[['Date','Sub Category','Transaction Type','Quantity','Invoice Total']].copy()\n",
    "df=df.rename(columns={'Sub Category':'Category'})\n",
    "df=df.rename(columns={'Invoice Total':'Total sales (Dollar)'})\n",
    "df=df[df['Transaction Type']=='Sale']\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "df['Date']=df['Date'].dt.date"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "19a9237eea1e7f3f",
   "metadata": {},
   "source": [
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f17b62461a68fb0e",
   "metadata": {},
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Date'].dt.year.nunique()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b744e73a7c9d1c02",
   "metadata": {},
   "source": [
    "daily_df = df.groupby(['Date','Category'])['Quantity'].sum().reset_index()\n",
    "daily_df['Date']=pd.to_datetime(daily_df['Date'])\n",
    "daily_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "58fc5a5d937281a0",
   "metadata": {},
   "source": [
    "daily_df['Category'].nunique()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a54d2111fb1a6362",
   "metadata": {},
   "source": [
    "### Sales in 2023"
   ]
  },
  {
   "cell_type": "code",
   "id": "40c03ba808641162",
   "metadata": {},
   "source": [
    "df_2023=daily_df[daily_df['Date'].dt.year==2023]\n",
    "#top 5 sales item\n",
    "top_5=df_2023.groupby('Category')['Quantity'].sum().nlargest(5).reset_index()\n",
    "top_5"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "596bb37369b86c3f",
   "metadata": {},
   "source": [
    "### The sales pattern of most five sale Items in 2023"
   ]
  },
  {
   "cell_type": "code",
   "id": "94b935744a65afb7",
   "metadata": {},
   "source": [
    "my_holidays = holidays.US()\n",
    "for item in top_5['Category'].unique():\n",
    "\n",
    "    item_df = df_2023[df_2023['Category'] == item].copy()\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(item_df['Date'], item_df['Quantity'])\n",
    "\n",
    "    item_df['Holiday_Name'] = item_df['Date'].apply(lambda d: my_holidays.get(d, None))\n",
    "    holiday_df = item_df[item_df['Holiday_Name'].notna()]\n",
    "\n",
    "    if not holiday_df.empty:\n",
    "        for _, row in holiday_df.iterrows():\n",
    "            plt.scatter(row['Date'], row['Quantity'], color='red', s=90, label=row['Holiday_Name'])\n",
    "            plt.text(row['Date'], row['Quantity'], row['Holiday_Name'], fontsize=8, color='red', ha='left', va='bottom')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "\n",
    "    plt.title(f\"{item} — 2023\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Quantity\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    if not holiday_df.empty:\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        unique = dict(zip(labels, handles))\n",
    "        plt.legend(unique.values(), unique.keys())   # remove duplicates\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cff65f9e0d0253c7",
   "metadata": {},
   "source": [
    "### Pants_and_Jeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da62679c99842f8",
   "metadata": {},
   "source": [
    "### 1.The pattern sale of Pants_and_Jeans top peak month"
   ]
  },
  {
   "cell_type": "code",
   "id": "da60fa682aa1a7d9",
   "metadata": {},
   "source": [
    "my_holidays = holidays.US()\n",
    "# Filter Pants & Jeans\n",
    "Pants_and_Jeans_df = df_2023[df_2023['Category'] == 'Pants and Jeans'].copy()\n",
    "\n",
    "# Add holiday names\n",
    "Pants_and_Jeans_df['Holiday_Name'] = Pants_and_Jeans_df['Date'].apply(\n",
    "    lambda d: my_holidays.get(d, None)\n",
    ")\n",
    "\n",
    "# Extract only rows where there is a holiday\n",
    "holidays = Pants_and_Jeans_df.dropna(subset=['Holiday_Name'])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(\n",
    "    Pants_and_Jeans_df['Date'],\n",
    "    Pants_and_Jeans_df['Quantity'],\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "# Add holiday markers\n",
    "plt.scatter(\n",
    "    holidays['Date'],\n",
    "    holidays['Quantity'],\n",
    "    s=120,\n",
    "    marker='o',\n",
    "    color='red'\n",
    ")\n",
    "\n",
    "# Add labels for each holiday marker\n",
    "for _, row in holidays.iterrows():\n",
    "    plt.annotate(\n",
    "        row['Holiday_Name'],\n",
    "        (row['Date'], row['Quantity']),\n",
    "        xytext=(0, 12),\n",
    "        textcoords='offset points',\n",
    "        ha='center',\n",
    "        fontsize=9,\n",
    "        color='red'\n",
    "    )\n",
    "\n",
    "# Labels and formatting\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Quantity')\n",
    "plt.title('Pants and Jeans — 2023')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3da77d6381b64608",
   "metadata": {},
   "source": [
    "jan = Pants_and_Jeans_df[Pants_and_Jeans_df['Date'].dt.month == 1]\n",
    "sep = Pants_and_Jeans_df[Pants_and_Jeans_df['Date'].dt.month == 9]\n",
    "dec = Pants_and_Jeans_df[Pants_and_Jeans_df['Date'].dt.month == 12]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12), sharey=False)\n",
    "\n",
    "datasets = [(jan, \"January\"), (sep, \"September\"), (dec, \"December\")]\n",
    "\n",
    "for ax, (df, month_name) in zip(axes, datasets):\n",
    "    ax.plot(df['Date'], df['Quantity'], marker='o')\n",
    "    df['Holiday_Name'] = df['Date'].apply(lambda d: my_holidays.get(d, None))\n",
    "    holiday_df = df[df['Holiday_Name'].notna()]   # Keep only holidays\n",
    "\n",
    "    if not holiday_df.empty:\n",
    "        ax.scatter(\n",
    "            holiday_df['Date'],\n",
    "            holiday_df['Quantity'],\n",
    "            color='red',\n",
    "            s=80,\n",
    "            label='Holiday'\n",
    "        )\n",
    "\n",
    "        for _, row in holiday_df.iterrows():\n",
    "            ax.text(\n",
    "                row['Date'],\n",
    "                row['Quantity'],\n",
    "                f\"{row['Holiday_Name']}\",\n",
    "                fontsize=8,\n",
    "                color='red',\n",
    "                ha='left',\n",
    "                va='bottom'\n",
    "            )\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%b'))\n",
    "\n",
    "    ax.set_title(f\"Pants and Jeans — {month_name} 2023\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Quantity\")\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    if not holiday_df.empty:\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c8d0c9b7692ffb6a",
   "metadata": {},
   "source": [
    "### Check the trend at Weekly"
   ]
  },
  {
   "cell_type": "code",
   "id": "977d8217c4d0d7cf",
   "metadata": {},
   "source": [
    "x = df_2023.copy()\n",
    "x['Date'] = pd.to_datetime(x['Date'])\n",
    "x = x.set_index('Date')\n",
    "\n",
    "weekly_df = (\n",
    "    x[x['Category']=='Pants and Jeans']\n",
    "    .resample('w')\n",
    "    .sum()\n",
    ").reset_index()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(weekly_df['Date'], weekly_df['Quantity'], marker='o')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Quantity')\n",
    "plt.title('Pants and Jeans in 2023 (weekly_df)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b8c775769c1bd253",
   "metadata": {},
   "source": [
    "x = df.copy()\n",
    "x['Date'] = pd.to_datetime(x['Date'])\n",
    "x = x.set_index('Date')\n",
    "\n",
    "weekly_df = (\n",
    "    x[x['Category']=='Pants and Jeans']\n",
    "    .resample('Q')\n",
    "    .sum()\n",
    ").reset_index()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(weekly_df['Date'], weekly_df['Quantity'], marker='o')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Quantity')\n",
    "plt.title('Pants and Jeans in 2023-2025 (weekly_df)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "90dcd406783bc483",
   "metadata": {},
   "source": [
    "### Check the trend at Quarterly"
   ]
  },
  {
   "cell_type": "code",
   "id": "3654e95bad6ada93",
   "metadata": {},
   "source": [
    "df_2023"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c3e5853c76970d8a",
   "metadata": {},
   "source": [
    "x = df_2023.copy()\n",
    "x['Date'] = pd.to_datetime(x['Date'])\n",
    "x = x.set_index('Date')\n",
    "\n",
    "quarterly_df = (\n",
    "    x[x['Category']=='Pants and Jeans']\n",
    "    .resample('Q')\n",
    "    .sum()\n",
    ").reset_index()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(quarterly_df['Date'], quarterly_df['Quantity'], marker='o')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Quantity')\n",
    "plt.title('Pants and Jeans in 2023 (Quarterly)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8cca3ad3e191726d",
   "metadata": {},
   "source": [
    "y = df.copy()\n",
    "y['Date'] = pd.to_datetime(y['Date'])\n",
    "y = y.set_index('Date')\n",
    "\n",
    "quarterly_df = (\n",
    "    y[y['Category']=='Pants and Jeans']\n",
    "    .resample('Q')\n",
    "    .sum()\n",
    ").reset_index()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(quarterly_df['Date'], quarterly_df['Quantity'], marker='o')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Quantity')\n",
    "plt.title('Pants and Jeans in 2023 - 2025 (Quarterly)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff0b6a96d5fdd80a",
   "metadata": {},
   "source": [
    "merged"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1db44a6b4dc7ba92",
   "metadata": {},
   "source": [
    "### Train and test data"
   ]
  },
  {
   "cell_type": "code",
   "id": "1e01f27b08465353",
   "metadata": {},
   "source": [
    "df=merged[['Date','Category','Size','Color_x','Discount','Quantity','Sub Category']].copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "de3d336768801206",
   "metadata": {},
   "source": [
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "993bc179c5f5dbe2",
   "metadata": {},
   "source": [
    "#Handle null and duplicate\n",
    "null_count=df.isnull().sum()\n",
    "df=df.dropna(subset=['Size', 'Color_x'])\n",
    "null_count"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3bd5e8d1",
   "metadata": {},
   "source": [
    "# df['Date']=pd.to_datetime(df['Date'])\n",
    "# df['Date']=df['Date'].dt.date\n",
    "# df['Date']=pd.to_datetime(df['Date'])\n",
    "# allowed_sizes = ['M', 'L', 'S', 'XL', 'XXL']\n",
    "# df = df[df['Size'].isin(allowed_sizes)]\n",
    "# df =  df.groupby(['Date','Category','Size','Color_x'])[['Discount','Quantity']].sum() .reset_index()\n",
    "# df = df.rename(columns={'Quantity': 'Total sales'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9809a8b68dfc57fd",
   "metadata": {},
   "source": [
    "#feature engineer\n",
    "import holidays\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['day_of_year'] = df['Date'].dt.dayofyear\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "df['day_of_week'] = df['Date'].dt.dayofweek\n",
    "df['week_of_year'] = df['Date'].dt.isocalendar().week.astype(int)\n",
    "df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)\n",
    "df['is_month_end'] = df['Date'].dt.is_month_end.astype(int)\n",
    "df['is_month_start'] = df['Date'].dt.is_month_start.astype(int)\n",
    "\n",
    "for col in ['Category','Size','Color_x','Sub Category']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values('Date')\n",
    "\n",
    "# Lag features\n",
    "df['lag_1'] = df['Quantity'].shift(1) #sales of one day ago\n",
    "df['lag_7'] = df['Quantity'].shift(7) #sales of seven days ago\n",
    "df['lag_30'] = df['Quantity'].shift(30) #sales of one month ago\n",
    "df['rolling_7'] = df['Quantity'].rolling(7).mean() #The avg sales of seven sales\n",
    "df['rolling_30'] = df['Quantity'].rolling(30).mean()  #The avg sales of 30 sales\n",
    "df=df.dropna()\n",
    "\n",
    "# Holiday\n",
    "country_holidays = holidays.US()\n",
    "df['is_holiday'] = df['Date'].isin(country_holidays).astype(int)\n",
    "df['is_holiday_tomorrow']=df['Date'].shift(-1).isin(country_holidays).astype(int)\n",
    "df['is_holiday_yesterday']=df['Date'].shift(1).isin(country_holidays).astype(int)\n",
    "#big sale events\n",
    "df['zscore'] = (df['Quantity'] - df['Quantity'].mean()) / df['Quantity'].std()\n",
    "df['big_sale_event'] = (df['zscore'] > 2.5).astype(int)\n",
    "df = df.drop(columns=['month', 'zscore'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "769134c3babb3201",
   "metadata": {},
   "source": [
    "df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f648bbd80b6f2d8d",
   "metadata": {},
   "source": [
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4d225285ea0ca086",
   "metadata": {},
   "source": [
    "# Train/Test split\n",
    "train = df[df['Date'] < '2025-1-01']\n",
    "test = df[df['Date'] >= '2025-1-01']\n",
    "\n",
    "X_train = train.drop(['Date','Quantity'], axis=1)\n",
    "y_train = train['Quantity']\n",
    "\n",
    "X_test = test.drop(['Date','Quantity'], axis=1)\n",
    "y_test = test['Quantity']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1e090375b4fd75db",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8416bb72320e",
   "metadata": {},
   "source": [
    "### 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "id": "41493e5c667592a7",
   "metadata": {},
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_absolute_percentage_error\n",
    "model = XGBRegressor(\n",
    "    n_estimators=10000,        # number of trees\n",
    "    learning_rate=0.05,     # shrinkage rate\n",
    "    max_depth=6,            # tree depth\n",
    "    min_child_weight=1,     # minimum data in child node\n",
    "    subsample=0.8,          # row sampling\n",
    "    colsample_bytree=0.8,   # feature sampling\n",
    "    gamma=0,                # min loss reduction (split)\n",
    "    reg_alpha=0.0,          # L1 regularization\n",
    "    reg_lambda=1.0,         # L2 regularization\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred_value = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, pred_value)\n",
    "mape = mean_absolute_percentage_error(y_test, pred_value) * 100\n",
    "print(\"Test MAE:\", mae)\n",
    "print(\"Test MAPE:\", mape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2c49e7021396d578",
   "metadata": {},
   "source": [
    "### 2. Catboost"
   ]
  },
  {
   "cell_type": "code",
   "id": "cfc85bb551b16652",
   "metadata": {},
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model = CatBoostRegressor(\n",
    "    iterations=10000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=3.0,\n",
    "    loss_function='RMSE',\n",
    "    random_state=42,\n",
    "    bootstrap_type='Bayesian',   # keep Bayesian\n",
    "    bagging_temperature=1.0,     # controls Bayesian sampling\n",
    "    thread_count=-1,\n",
    "    verbose=False\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "pred_value = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, pred_value)\n",
    "mape = mean_absolute_percentage_error(y_test, pred_value) * 100\n",
    "print(\"Test MAE:\", mae)\n",
    "print(\"Test MAPE:\", mape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "df55f69a",
   "metadata": {},
   "source": [
    "### Improve the accuracy: \n",
    "1. Feature Engineering: create features that reveal trends, seasonality, cycles, events, and context: Done\n",
    "2. Better Train–Test Splitting (Time-Aware): NEVER use shuffle=True in time-series.\n",
    "3. Handle Outliers in Sales Data\n",
    "4. Target Transformation\n",
    "5. Reduce Noise in Features\n",
    "6. Train Separate Models per Product / Category\n",
    "7. Cross-validation for time-series: Use TimeSeriesSplit instead of simple train/test\n",
    "8. Hyperparameter:\n",
    "    - max_depth: More depth → more complex trees → better learning (but risk overfitting)\n",
    "    - min_child_weight:Lower values → more sensitive splits → captures rare patterns.\n",
    "    - learning_rate + n_estimators: Lower learning rate → more accurate but slower\n",
    "    - subsample & colsample_bytree: These reduce overfitting and increase generalization.\n",
    "    - gamma: helps prune unnecessary splits.\n",
    "    - reg_alpha & reg_lambda: Regularization keeps trees from overfitting"
   ]
  },
  {
   "cell_type": "code",
   "id": "e4b25933efb7a0e9",
   "metadata": {},
   "source": [
    "# Improve the accuracy: \n",
    "1. "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd2d9257",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ennovar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
